{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import Image\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lasagne import utils\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_seed(n):\n",
    "    np.random.seed(n)\n",
    "    lasagne.random.set_rng(np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None, BN=False):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, sz, sz),\n",
    "                                     input_var=input_var)\n",
    "    if BN:\n",
    "        l_in = lasagne.layers.batch_norm(l_in)\n",
    "\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    if BN:\n",
    "        l_hid1 = lasagne.layers.batch_norm(l_hid1)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid2 = lasagne.layers.batch_norm(l_hid2)\n",
    "        \n",
    "    l_hid3 = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid3 = lasagne.layers.batch_norm(l_hid3)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid3, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    subprocess.call(['th', '-l', 'my_example'])\n",
    "    n, d = 10000, 3600\n",
    "    train_images = np.zeros((n, d), dtype=np.uint8)\n",
    "    train_labels = np.zeros(n, dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        image_open = Image.open(\"clMNIST/example\" + str(i) + \".png\")\n",
    "        a = np.array(image_open.getdata())\n",
    "        train_images[i] = a \n",
    "        train_labels[i] = np.uint(np.loadtxt(\"clMNIST/y\" + str(i)))\n",
    "    return np.reshape(train_images, (-1, 1, 60, 60)), np.ravel(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adam_update(loss_or_grads, params, learning_rate=1e-3, beta1=0.9,\n",
    "                        beta2=0.999, epsilon=1e-8):\n",
    "    all_grads = lasagne.updates.get_or_compute_grads(loss_or_grads, params)\n",
    "    t_prev = theano.shared(utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1 * m_prev + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_prev + (1 - beta2) * g_t ** 2\n",
    "        step = a_t * m_t / (T.sqrt(v_t) + epsilon)\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates\n",
    "\n",
    "\n",
    "def adam_update2(loss_or_grads, params, learning_rate=1e-3, beta1=0.9,\n",
    "                 beta2=0.999, epsilon=1e-6):\n",
    "    all_grads = lasagne.updates.get_or_compute_grads(loss_or_grads, params)\n",
    "\n",
    "\n",
    "    t_prev = theano.shared(utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1 * m_prev + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_prev + (1 - beta2) * g_t ** 2\n",
    "        step = a_t * m_t / (T.sqrt(v_t + epsilon))\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_method(method, model='mlp', BN=False, num_epochs=50, alpha=0.1, mu=0.9, beta1=0.9, beta2=0.999, echo=False, \n",
    "               batch_size=100, epsilon=1e-8):\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    if echo:\n",
    "        print(\"Building model and compiling functions...\")\n",
    "    if model == 'mlp':\n",
    "        network = build_mlp(input_var, BN)\n",
    "    else:\n",
    "        print(\"Unrecognized model type %r.\" % model)\n",
    "        return\n",
    "\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    train_acc = T.mean(T.eq(T.argmax(prediction, axis=1), target_var),\n",
    "                 dtype=theano.config.floatX)\n",
    "\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "\n",
    "    if method == lasagne.updates.sgd:\n",
    "        updates = method(loss, params, learning_rate=alpha)\n",
    "    elif method == lasagne.updates.momentum:\n",
    "        updates = method(loss, params, learning_rate=alpha, momentum=mu)\n",
    "    elif method == lasagne.updates.adam:\n",
    "        updates = method(loss, params, learning_rate=alpha, beta1=beta1)\n",
    "    elif method == adam_update or method == adam_update2:\n",
    "        updates = method(loss, params, learning_rate=alpha, beta1=beta1, beta2=beta2, epsilon=epsilon)\n",
    "    else:\n",
    "        updates = method(loss, params, learning_rate=alpha, epsilon=epsilon)\n",
    "\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    train_fn_acc = theano.function([input_var, target_var], train_acc)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    if echo:\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    res = dict()\n",
    "    arr_train_err = []\n",
    "    arr_val_err = []\n",
    "    arr_train_acc = []\n",
    "    arr_val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        train_acc = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_inputs, train_targets = get_data()\n",
    "        \n",
    "        for batch in iterate_minibatches(train_inputs, train_targets, batch_size, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            err = train_fn(inputs, targets)\n",
    "            acc = train_fn_acc(inputs, targets)\n",
    "            train_err += err\n",
    "            train_acc += acc\n",
    "            train_batches += 1\n",
    "\n",
    "        arr_train_err.append(train_err / train_batches)\n",
    "        arr_train_acc.append(train_acc / train_batches * 100)\n",
    "        \n",
    "        val_inputs, val_targets = get_data()\n",
    "\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(val_inputs, val_targets, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        arr_val_err.append(val_err / val_batches)\n",
    "        arr_val_acc.append(val_acc / val_batches * 100)\n",
    "\n",
    "        if echo:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "#             print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "#             print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "#                 val_acc / val_batches * 100))\n",
    "\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    \n",
    "    test_inputs, test_targets = get_data()\n",
    "        \n",
    "    for batch in iterate_minibatches(test_inputs, test_targets, batch_size, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "\n",
    "    if echo:\n",
    "        print(\"Final results:\")\n",
    "        print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "        print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "            test_acc / test_batches * 100))\n",
    "\n",
    "    res['train_err'] = np.array(arr_train_err)\n",
    "    res['val_err'] = np.array(arr_val_err)\n",
    "    res['train_acc'] = np.array(arr_train_acc)\n",
    "    res['val_acc'] = np.array(arr_val_acc)\n",
    "    res['test_err'] = test_err / test_batches\n",
    "    res['test_acc'] = test_acc / test_batches * 100\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 57s, sys: 7min 45s, total: 25min 43s\n",
      "Wall time: 24min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "adagrad = run_method(lasagne.updates.adagrad, num_epochs=50, alpha=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('adagrad', 'rb') as f:\n",
    "    adagrad = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 24s, sys: 16min 17s, total: 37min 41s\n",
      "Wall time: 28min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "bn_adagrad = run_method(lasagne.updates.adagrad, num_epochs=50, alpha=1e-1, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('adagrad', 'wb') as f:\n",
    "    pickle.dump(adagrad, f)\n",
    "    pickle.dump(bn_adagrad, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(momentum['train_acc'], 'b--')\n",
    "plt.plot(momentum['val_acc'], 'b')\n",
    "plt.plot(bn_momentum['train_acc'], 'r--')\n",
    "plt.plot(bn_momentum['val_acc'], 'r')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlim(xmax=49)\n",
    "plt.legend(['Momentum train', 'Momentum validation', 'BN Momentum train', 'BN Momentum validation'], loc=0, fontsize=12)\n",
    "plt.title('Momentum, 3HL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 58s, sys: 10min 3s, total: 28min 1s\n",
      "Wall time: 25min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "adadelta = run_method(lasagne.updates.adadelta, num_epochs=50, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 28s, sys: 17min 22s, total: 37min 50s\n",
      "Wall time: 28min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "bn_adadelta = run_method(lasagne.updates.adadelta, num_epochs=50, alpha=1.0, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('adadelta', 'wb') as f:\n",
    "    pickle.dump(adadelta, f)\n",
    "    pickle.dump(bn_adadelta, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 40s, sys: 8min 37s, total: 26min 18s\n",
      "Wall time: 23min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "rmsprop = run_method(lasagne.updates.rmsprop, num_epochs=50, alpha=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 32s, sys: 16min 13s, total: 36min 46s\n",
      "Wall time: 24min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "bn_rmsprop = run_method(lasagne.updates.rmsprop, num_epochs=50, alpha=1e-2, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('rmsprop', 'wb') as f:\n",
    "    pickle.dump(rmsprop, f)\n",
    "    pickle.dump(bn_rmsprop, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 12s, sys: 5min 13s, total: 20min 26s\n",
      "Wall time: 21min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "sgd = run_method(lasagne.updates.sgd, num_epochs=50, alpha=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 7s, sys: 12min 10s, total: 30min 17s\n",
      "Wall time: 23min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "bn_sgd = run_method(lasagne.updates.sgd, num_epochs=50, alpha=1.0, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sgd', 'wb') as f:\n",
    "    pickle.dump(sgd, f)\n",
    "    pickle.dump(bn_sgd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 9s, sys: 4min 39s, total: 19min 48s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "momentum = run_method(lasagne.updates.momentum, num_epochs=50, alpha=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 58s, sys: 11min 38s, total: 29min 37s\n",
      "Wall time: 20min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(100)\n",
    "bn_momentum = run_method(lasagne.updates.momentum, num_epochs=50, alpha=1.0, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('momentum', 'wb') as f:\n",
    "    pickle.dump(momentum, f)\n",
    "    pickle.dump(bn_momentum, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
