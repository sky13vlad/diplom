{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import Image\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lasagne import utils\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_seed(n):\n",
    "    np.random.seed(n)\n",
    "    lasagne.random.set_rng(np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adam_update(loss_or_grads, params, learning_rate=1e-3, beta1=0.9,\n",
    "                        beta2=0.999, epsilon=1e-4):\n",
    "    all_grads = lasagne.updates.get_or_compute_grads(loss_or_grads, params)\n",
    "    t_prev = theano.shared(utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1 * m_prev + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_prev + (1 - beta2) * g_t ** 2\n",
    "        step = a_t * m_t / (T.sqrt(v_t) + epsilon)\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None, BN=False):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, sz, sz),\n",
    "                                     input_var=input_var)\n",
    "    if BN:\n",
    "        l_in = lasagne.layers.batch_norm(l_in)\n",
    "\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    if BN:\n",
    "        l_hid1 = lasagne.layers.batch_norm(l_hid1)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid2 = lasagne.layers.batch_norm(l_hid2)\n",
    "        \n",
    "    l_hid3 = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid3 = lasagne.layers.batch_norm(l_hid3)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid3, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    subprocess.call(['th', '-l', 'my_example'])\n",
    "    n, d = 10000, 3600\n",
    "    train_images = np.zeros((n, d), dtype=np.uint8)\n",
    "    train_labels = np.zeros(n, dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        image_open = Image.open(\"clMNIST/example\" + str(i) + \".png\")\n",
    "        a = np.array(image_open.getdata())\n",
    "        train_images[i] = a \n",
    "        train_labels[i] = np.uint(np.loadtxt(\"clMNIST/y\" + str(i)))\n",
    "    return np.reshape(train_images, (-1, 1, 60, 60)), np.ravel(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_method(method, model='mlp', BN=False, num_epochs=50, alpha=0.1, mu=0.9, beta1=0.9, beta2=0.999, echo=False, \n",
    "               batch_size=100):\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    if echo:\n",
    "        print(\"Building model and compiling functions...\")\n",
    "    if model == 'mlp':\n",
    "        network = build_mlp(input_var, BN)\n",
    "    else:\n",
    "        print(\"Unrecognized model type %r.\" % model)\n",
    "        return\n",
    "\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    train_acc = T.mean(T.eq(T.argmax(prediction, axis=1), target_var),\n",
    "                 dtype=theano.config.floatX)\n",
    "\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "\n",
    "    if method == lasagne.updates.sgd:\n",
    "        updates = method(loss, params, learning_rate=alpha)\n",
    "    elif method == lasagne.updates.momentum:\n",
    "        updates = method(loss, params, learning_rate=alpha, momentum=mu)\n",
    "    elif method == lasagne.updates.adam:\n",
    "        updates = method(loss, params, learning_rate=alpha, beta1=beta1)\n",
    "    elif method == adam_update or method == adam_update2:\n",
    "        updates = method(loss, params, learning_rate=alpha, beta1=beta1, beta2=beta2)\n",
    "    else:\n",
    "        updates = method(loss, params, learning_rate=alpha)\n",
    "\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    train_fn_acc = theano.function([input_var, target_var], train_acc)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    if echo:\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    res = dict()\n",
    "    arr_train_err = []\n",
    "    arr_val_err = []\n",
    "    arr_train_acc = []\n",
    "    arr_val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        train_acc = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_inputs, train_targets = get_data()\n",
    "        \n",
    "        for batch in iterate_minibatches(train_inputs, train_targets, batch_size, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            err = train_fn(inputs, targets)\n",
    "            acc = train_fn_acc(inputs, targets)\n",
    "            train_err += err\n",
    "            train_acc += acc\n",
    "            train_batches += 1\n",
    "\n",
    "        arr_train_err.append(train_err / train_batches)\n",
    "        arr_train_acc.append(train_acc / train_batches * 100)\n",
    "        \n",
    "        val_inputs, val_targets = get_data()\n",
    "\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(val_inputs, val_targets, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        arr_val_err.append(val_err / val_batches)\n",
    "        arr_val_acc.append(val_acc / val_batches * 100)\n",
    "\n",
    "        if echo:\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "            print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "#             print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "#             print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "#                 val_acc / val_batches * 100))\n",
    "\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    \n",
    "    test_inputs, test_targets = get_data()\n",
    "        \n",
    "    for batch in iterate_minibatches(test_inputs, test_targets, batch_size, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "\n",
    "    if echo:\n",
    "        print(\"Final results:\")\n",
    "        print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "        print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "            test_acc / test_batches * 100))\n",
    "\n",
    "    res['train_err'] = np.array(arr_train_err)\n",
    "    res['val_err'] = np.array(arr_val_err)\n",
    "    res['train_acc'] = np.array(arr_train_acc)\n",
    "    res['val_acc'] = np.array(arr_val_acc)\n",
    "    res['test_err'] = test_err / test_batches\n",
    "    res['test_acc'] = test_acc / test_batches * 100\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 31s, sys: 9min 22s, total: 30min 53s\n",
      "Wall time: 30min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam1 = run_method(adam_update, num_epochs=50, alpha=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 15s, sys: 8min 33s, total: 26min 49s\n",
      "Wall time: 24min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam2 = run_method(adam_update, num_epochs=50, alpha=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 27s, sys: 8min 6s, total: 25min 34s\n",
      "Wall time: 22min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam3 = run_method(adam_update, num_epochs=50, alpha=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 22s, sys: 8min 13s, total: 25min 36s\n",
      "Wall time: 22min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam4 = run_method(adam_update, num_epochs=50, alpha=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 52s, sys: 8min 14s, total: 26min 7s\n",
      "Wall time: 23min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam5 = run_method(adam_update, num_epochs=50, alpha=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 40s, sys: 8min 7s, total: 25min 47s\n",
      "Wall time: 22min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "adam6 = run_method(adam_update, num_epochs=50, alpha=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('lrate_adam', 'wb') as f:\n",
    "    pickle.dump(adam1, f)\n",
    "    pickle.dump(adam2, f)\n",
    "    pickle.dump(adam3, f)\n",
    "    pickle.dump(adam4, f)\n",
    "    pickle.dump(adam5, f)\n",
    "    pickle.dump(adam6, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 52s, sys: 15min 59s, total: 36min 52s\n",
      "Wall time: 25min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_seed(1)\n",
    "bn_adam = run_method(adam_update, num_epochs=50, alpha=1e-3, BN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bn_adam', 'wb') as f:\n",
    "    pickle.dump(bn_adam, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(adam3['train_acc'], 'b--')\n",
    "plt.plot(adam3['val_acc'], 'b')\n",
    "plt.plot(bn_adam['train_acc'], 'r--')\n",
    "plt.plot(bn_adam['val_acc'], 'r')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlim(xmax=49)\n",
    "plt.legend(['Adam 1e-3 train', 'Adam 1e-3 validation', 'BN Adam 1e-3 train', 'BN Adam 1e-3 validation'], loc=0, fontsize=12)\n",
    "plt.title('Adam comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(adam1['val_acc'], 'b')\n",
    "plt.plot(adam2['val_acc'], 'g')\n",
    "plt.plot(adam3['val_acc'], 'r')\n",
    "plt.plot(adam4['val_acc'], 'k')\n",
    "plt.plot(adam5['val_acc'], 'y')\n",
    "plt.plot(adam6['val_acc'], 'c')\n",
    "plt.xlim(xmax=49)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Adam validation accuracy, different alpha')\n",
    "plt.legend(['1e-4', '5e-4', '1e-3', '5e-3', '1e-2', '1e-1'], loc=0, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
