{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import Image\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lasagne import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    n, d = 500000, 3600\n",
    "    train_images = np.zeros((n, d), dtype=np.uint8)\n",
    "    train_labels = np.zeros(n, dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        image_open = Image.open(\"clMNIST/example\" + str(i) + \".png\")\n",
    "        a = np.array(image_open.getdata())\n",
    "        train_images[i] = a \n",
    "        train_labels[i] = np.uint(np.loadtxt(\"clMNIST/y\" + str(i)))\n",
    "        del(image_open)\n",
    "        del(a)\n",
    "    return np.reshape(train_images, (-1, 1, 60, 60)), np.ravel(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 48s, sys: 31.5 s, total: 6min 20s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_input, train_target = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_input, data_target = train_input, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input, test_target = data_input[400000:], data_target[400000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_input, val_target = data_input[300000:400000], data_target[300000:400000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input, train_target = data_input[:300000], data_target[:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_seed(n):\n",
    "    np.random.seed(n)\n",
    "    lasagne.random.set_rng(np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adam_update(loss_or_grads, params, learning_rate=1e-3, beta1=0.9,\n",
    "                        beta2=0.999, epsilon=1e-8):\n",
    "    all_grads = lasagne.updates.get_or_compute_grads(loss_or_grads, params)\n",
    "    t_prev = theano.shared(utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1 * m_prev + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_prev + (1 - beta2) * g_t ** 2\n",
    "        step = a_t * m_t / (T.sqrt(v_t) + epsilon)\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates\n",
    "\n",
    "\n",
    "def adam_update2(loss_or_grads, params, learning_rate=1e-3, beta1=0.9,\n",
    "                 beta2=0.999, epsilon=1e-6):\n",
    "    all_grads = lasagne.updates.get_or_compute_grads(loss_or_grads, params)\n",
    "\n",
    "\n",
    "    t_prev = theano.shared(utils.floatX(0.))\n",
    "    updates = OrderedDict()\n",
    "\n",
    "    t = t_prev + 1\n",
    "    a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n",
    "\n",
    "    for param, g_t in zip(params, all_grads):\n",
    "        value = param.get_value(borrow=True)\n",
    "        m_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "        v_prev = theano.shared(np.zeros(value.shape, dtype=value.dtype),\n",
    "                               broadcastable=param.broadcastable)\n",
    "\n",
    "        m_t = beta1 * m_prev + (1 - beta1) * g_t\n",
    "        v_t = beta2 * v_prev + (1 - beta2) * g_t ** 2\n",
    "        step = a_t * m_t / (T.sqrt(v_t + epsilon))\n",
    "\n",
    "        updates[m_prev] = m_t\n",
    "        updates[v_prev] = v_t\n",
    "        updates[param] = param - step\n",
    "\n",
    "    updates[t_prev] = t\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None, BN=False):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, sz, sz),\n",
    "                                     input_var=input_var)\n",
    "    if BN:\n",
    "        l_in = lasagne.layers.batch_norm(l_in)\n",
    "\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    if BN:\n",
    "        l_hid1 = lasagne.layers.batch_norm(l_hid1)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid2 = lasagne.layers.batch_norm(l_hid2)\n",
    "        \n",
    "    l_hid3 = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=100,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    if BN:\n",
    "        l_hid3 = lasagne.layers.batch_norm(l_hid3)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid3, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
