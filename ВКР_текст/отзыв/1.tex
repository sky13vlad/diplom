\documentclass[12pt,oneside]{article}

\usepackage[russian]{babel}
\usepackage[cp1251]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[12pt]{extsizes}
\usepackage[linesnumbered,boxed]{algorithm2e}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{epstopdf}


\binoppenalty = 10000
\relpenalty = 10000
\textheight = 23cm
\textwidth = 17cm
\oddsidemargin = 0pt
\topmargin = -1.5cm
\parskip = 0pt
\tolerance = 2000
\flushbottom

\pagestyle{myheadings}

\begin{document}



\begin{center}
Отзыв\\
научного руководителя на выпускную квалификационную работу \\
"Модификации метода стохастического градиентного спуска для задач машинного обучения с большими объемами данных"\\
студента 417 группы \\
факультета Вычислительной математики и кибернетики\\
МГУ им. М. В. Ломоносова\\
Чабаненко Владислава Дмитриевича\\
\end{center}
\bigskip

\begin{flushleft}
В выпускной квалификационной работе рассматривается актуальная тема стохастических оптимизаций для задач машинного обучения, а именно, исследуется свежая разработка для ускорения обучения искусственных нейронных сетей, называемая батч-нормализацией. 

Работа состоит из введения, теоретического и экспериментального разделов и заключения. Во введении автор описывает актуальность выбранной темы и мотивирует постановку своего  исследования. Первая часть теоретического раздела раскрывает определение искуственных нейронных сетей, объясняет понятия, используемые в работе. Вторая часть теоретического раздела описывает стандартный метод для обучения нейронных сетей с большими объемами данных, указывает на его недостатки и вводит как формально, так и интуитивно, его наиболее популярные модификации. Третья часть теоретического раздела раскрывает проблемы, возникающие при обучении нейронных сетей, и объясняет суть батч-нормализации --- модификации структуры нейронной сети, устраняющей эти проблемы. Раздел с экспериментами состоит из четырех частей. Первые две части описывают используемые в ходе работы датасеты и архитектуры нейронных сетей. В третьей части автор подробно описывает выдвинутые гипотезы и постановки экспериментов. Четвертая часть раздела содержит результаты экспериментов и сделанные из них выводы. 

Структура работы хорошо продумана, материал излагается последовательно и легко читается. В качестве замечания можно отметить, что в работе отсутствует подтверждение выводов о сложности совмещения батч-нормализации и метода Adam. Развитие этой темы можно порекомендовать, как направление для дальнейшей работы.\\

В ходе работы Владислав проявил высокий уровень самостоятельности, продемонстрировал умение проводить поиск релевантной литературы, разрабатывать дизайн экспериментов.

Считаю, что работа заслуживает оценки "отлично".\\
\end{flushleft}


\begin{flushleft}
Научный руководитель\\
ученый секретарь каф. ММП ВМК МГУ\\
научный сотрудник\\
Д. А. Кропотов\\

5 мая 2016 г.
\end{flushleft}

\end{document}
