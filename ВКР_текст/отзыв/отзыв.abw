<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE abiword PUBLIC "-//ABISOURCE//DTD AWML 1.0 Strict//EN" "http://www.abisource.com/awml.dtd">
<abiword template="false" xmlns:ct="http://www.abisource.com/changetracking.dtd" xmlns:fo="http://www.w3.org/1999/XSL/Format" xmlns:math="http://www.w3.org/1998/Math/MathML" xid-max="37" xmlns:dc="http://purl.org/dc/elements/1.1/" styles="unlocked" fileformat="1.0" xmlns:svg="http://www.w3.org/2000/svg" xmlns:awml="http://www.abisource.com/awml.dtd" xmlns="http://www.abisource.com/awml.dtd" xmlns:xlink="http://www.w3.org/1999/xlink" version="0.99.2" xml:space="preserve" props="dom-dir:ltr; document-footnote-restart-section:0; document-endnote-type:numeric; document-endnote-place-enddoc:1; document-endnote-initial:1; lang:en-US; document-endnote-restart-section:0; document-footnote-restart-page:0; document-footnote-type:numeric; document-footnote-initial:1; document-endnote-place-endsection:0">
<!-- ======================================================================== -->
<!-- This file is an AbiWord document.                                        -->
<!-- AbiWord is a free, Open Source word processor.                           -->
<!-- More information about AbiWord is available at http://www.abisource.com/ -->
<!-- You should not edit this file by hand.                                   -->
<!-- ======================================================================== -->

<metadata>
<m key="abiword.date_last_changed">Sun May  8 18:43:45 2016
</m>
<m key="abiword.generator">AbiWord</m>
<m key="dc.creator">vlad</m>
<m key="dc.date">Sun May  8 18:43:45 2016
</m>
<m key="dc.format">application/x-abiword</m>
</metadata>
<rdf>
</rdf>
<history version="1" edit-time="287" last-saved="1462722225" uid="fb0a31d0-1532-11e6-8200-8c1d999deb10">
<version id="1" started="1462722225" uid="a634bfb2-1533-11e6-8200-8c1d999deb10" auto="0" top-xid="37"/>
</history>
<styles>
<s type="P" name="Normal" followedby="Current Settings" props="font-family:Times New Roman; margin-top:0pt; color:000000; margin-left:0pt; text-position:normal; widows:2; font-style:normal; text-indent:0in; font-variant:normal; font-weight:normal; margin-right:0pt; font-size:12pt; text-decoration:none; margin-bottom:0pt; line-height:1.0; bgcolor:transparent; text-align:left; font-stretch:normal"/>
</styles>
<pagesize pagetype="Letter" orientation="portrait" width="8.500000" height="11.000000" units="in" page-scale="1.000000"/>
<section xid="36" props="page-margin-footer:0.5in; page-margin-header:0.5in">
<p style="Normal" xid="37" props="text-align:center"><c>Отзыв</c></p>
<p style="Normal" xid="2" props="text-align:center"><c>научного руководителя на выпускную квалификационную работу</c></p>
<p style="Normal" xid="3" props="text-align:center"><c>"Модификации метода стохастического градиентного спуска для задач машинного обучения с большими объемами данных"</c></p>
<p style="Normal" xid="4" props="text-align:center"><c>студента 417 группы </c></p>
<p style="Normal" xid="5" props="text-align:center"><c>факультета Вычислительной математики и кибернетики</c></p>
<p style="Normal" xid="6" props="text-align:center"><c>МГУ им. М. В. Ломоносова</c></p>
<p style="Normal" xid="7" props="text-align:center"><c>Чабаненко Владислава Дмитриевича</c></p>
<p style="Normal" xid="10"><c><br/></c></p>
<p style="Normal" xid="12"><c>В выпускной квалификационной работе рассматривается актуальная тема стохастических оптимизаций для задач машинного обучения, а именно, исследуется свежая разработка для ускорения обучения искусственных нейронных сетей, называемая батч-нормализацией. </c></p>
<p style="Normal" xid="34"><c></c></p>
<p style="Normal" xid="14"><c>Работа состоит из введения, теоретического и экспериментального разделов и заключения. Во введении автор описывает актуальность выбранной темы и мотивирует постановку своего  исследования. Первая часть теоретического раздела раскрывает определение искуственных нейронных сетей, объясняет понятия, используемые в работе. Вторая часть теоретического раздела описывает стандартный метод для обучения нейронных сетей с большими объемами данных, указывает на его недостатки и вводит как формально, так и интуитивно, его наиболее популярные модификации. Третья часть теоретического раздела раскрывает проблемы, возникающие при обучении нейронных сетей, и объясняет суть батч-нормализации --- модификации структуры нейронной сети, устраняющей эти проблемы. Раздел с экспериментами состоит из четырех частей. Первые две части описывают используемые в ходе работы датасеты и архитектуры нейронных сетей. В третьей части автор подробно описывает выдвинутые гипотезы и постановки экспериментов. Четвертая часть раздела содержит результаты экспериментов и сделанные из них выводы. </c></p>
<p style="Normal" xid="15"><c></c></p>
<p style="Normal" xid="16"><c>Структура работы хорошо продумана, материал излагается последовательно и легко читается. В качестве замечания можно отметить, что в работе отсутствует теоретическое подтверждение выводов о сложности совмещения батч-нормализации и метода Adam. Развитие этой темы можно порекомендовать, как направление для дальнейшей работы.</c></p>
<p style="Normal" xid="17"><c></c></p>
<p style="Normal" xid="18"><c>В ходе работы Владислав проявил высокий уровень самостоятельности, продемонстрировал умение проводить поиск релевантной литературы, разрабатывать дизайн экспериментов.</c></p>
<p style="Normal" xid="19"><c></c></p>
<p style="Normal" xid="20"><c>Считаю, что работа заслуживает оценки "отлично".</c></p>
<p style="Normal" xid="22"><c></c></p>
<p style="Normal" xid="35"><c></c></p>
<p style="Normal" xid="25"><c>Научный руководитель</c></p>
<p style="Normal" xid="26"><c>ученый секретарь каф. ММП ВМК МГУ</c></p>
<p style="Normal" xid="27"><c>научный сотрудник</c></p>
<p style="Normal" xid="28"><c>Д. А. Кропотов</c></p>
<p style="Normal" xid="29"><c><br/></c></p>
<p style="Normal" xid="30"><c>5 мая 2016 г.</c></p>
</section>
</abiword>
